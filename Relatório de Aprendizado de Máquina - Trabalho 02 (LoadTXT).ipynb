{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regressão Logística com Regularização\n",
    "\n",
    "Nesta parte do trabalho, será implementada a **_Regressão Logística Regularizada_**\n",
    "para prever se os microchips de uma usina de fabricação passam na garantia\n",
    "de qualidade (QA). Durante a QA, cada microchip passa por vários testes para\n",
    "garantir se está funcionando corretamente. Dessa forma, a Gestão de Produto da \n",
    "fábrica terá o resultados de teste para alguns microchips em dois testes diferentes. \n",
    "\n",
    "A partir desses dois testes, será determinado se os microchips deveriam ser \n",
    "aceitos ou rejeitados. Para auxiliar a tomar a decisão, há um conjunto de dados\n",
    "com resultados de testes anteriores sobre microchips, a partir do qual é possível construir\n",
    "um modelo de Regressão Logística.\n",
    "\n",
    "O arquivo {ex2data2.txt} contém os dados a serem usados nessa parte do trabalho. A primeira \n",
    "coluna corresponde aos resultados do primeiro teste, enquanto que a segunda coluna corresponde\n",
    "aos resultados do segundo teste. A terceira coluna contém os valores da classe (y = 0 significa \n",
    "rejeitado no teste, e y = 1 significa aceito no teste).\n",
    "\n",
    "## 1.1 Visualização dos Dados\n",
    "\n",
    "Para a maioria dos conjuntos de dados do mundo real, não é possível criar um gráfico para \n",
    "visualizar seus pontos. Mas, para o conjunto de dados fornecido, isso é possível. Implemente \n",
    "um script em _Python_ que produza um gráfico de dispersão (scatter plot) dos dados fornecidos. \n",
    "Após finalizado, seu script deve produzir um resultado similar ao apresentado na Figura abaixo.\n",
    "\n",
    "![ScatterPlot](scatter_plot2.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from numpy import loadtxt, where, append, zeros, ones, array, linspace, logspace\n",
    "from pylab import scatter, show, legend, xlabel, ylabel\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# Carregando o arquivo gerado pelo MATLAB\n",
    "#import scipy.io\n",
    "#mat = scipy.io.loadmat('file.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QATest1</th>\n",
       "      <th>QATest2</th>\n",
       "      <th>QAcceptance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.69956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.68494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.69225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.50219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.46564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    QATest1  QATest2  QAcceptance\n",
       "0  0.051267  0.69956            1\n",
       "1 -0.092742  0.68494            1\n",
       "2 -0.213710  0.69225            1\n",
       "3 -0.375000  0.50219            1\n",
       "4 -0.513250  0.46564            1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construindo um dataset com base num Dataframe, já identificando colunas e exibindo seus primeiros 20 registros.\n",
    "df = pd.read_csv('am-T2-dados/ex2data2.txt', names=['QATest1', 'QATest2', 'QAcceptance'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/1wauCv3AkQuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11763ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvr/kdS0EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117946ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1179d7630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização da Distribuição dos Dados conforme Histograma\n",
    "\n",
    "df.hist()\n",
    "plt.pyplot.show()\n",
    "\n",
    "df.QATest1.hist(), df.QATest2.hist(), df.QAcceptance.hist()\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QATest1</th>\n",
       "      <th>QATest2</th>\n",
       "      <th>QAcceptance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496654</td>\n",
       "      <td>0.519743</td>\n",
       "      <td>0.502060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.830070</td>\n",
       "      <td>-0.769740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.372120</td>\n",
       "      <td>-0.254385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.006336</td>\n",
       "      <td>0.213455</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.478970</td>\n",
       "      <td>0.646562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.070900</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          QATest1     QATest2  QAcceptance\n",
       "count  118.000000  118.000000   118.000000\n",
       "mean     0.054779    0.183102     0.491525\n",
       "std      0.496654    0.519743     0.502060\n",
       "min     -0.830070   -0.769740     0.000000\n",
       "25%     -0.372120   -0.254385     0.000000\n",
       "50%     -0.006336    0.213455     0.000000\n",
       "75%      0.478970    0.646562     1.000000\n",
       "max      1.070900    1.108900     1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.00\n",
       "mean       0.05\n",
       "std        0.50\n",
       "min       -0.83\n",
       "25%       -0.37\n",
       "50%       -0.01\n",
       "75%        0.48\n",
       "max        1.07\n",
       "Name: QATest1, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QATest1.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.00\n",
       "mean       0.18\n",
       "std        0.52\n",
       "min       -0.77\n",
       "25%       -0.25\n",
       "50%        0.21\n",
       "75%        0.65\n",
       "max        1.11\n",
       "Name: QATest2, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QATest2.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.00\n",
       "mean       0.49\n",
       "std        0.50\n",
       "min        0.00\n",
       "25%        0.00\n",
       "50%        0.00\n",
       "75%        1.00\n",
       "max        1.00\n",
       "Name: QAcceptance, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QAcceptance.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='QATest1', axis=1)\n",
    "df.drop(labels='QATest2', axis=1)\n",
    "df.drop(labels='QAcceptance', axis=1)\n",
    "\n",
    "\n",
    "#load the dataset\n",
    "data = loadtxt('am-T2-dados/ex2data2.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noIiISCT+P3v4XjCzEJHWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11738f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data[:, 0:2]\n",
    "y = data[:, 2]\n",
    "\n",
    "pos = where(y == 1)\n",
    "neg = where(y == 0)\n",
    "scatter(X[pos, 0], X[pos, 1], marker='+', c='xkcd:black', label='Not Admitted')\n",
    "scatter(X[neg, 0], X[neg, 1], marker='o', c='xkcd:yellow', label='Admitted')\n",
    "legend(['Admitted', 'Not Admitted'])\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Mapeamento de características (_feature mapping_)\n",
    "\n",
    "Uma maneira de tornar os dados mais apropriados para a classificação é criar\n",
    "mais características a partir das já existentes. Para isso, você deve criar uma\n",
    "função **`mapFeature`**. Essa função deve ser implementada em um arquivo de\n",
    "nome **_`mapFeature.py`_**, que irá mapear as características para todos os termos\n",
    "polinomiais de x1 e x2, até a sexta potência. Como resultado desse mapeamento, nosso \n",
    "vetor de duas características (os escores nos dois testes de QA) será transformado \n",
    "em um **vetor de _28 dimensões_**.\n",
    "\n",
    "Um classificador que usa regressão logística treinado nesse vetor de características \n",
    "de maior dimensão terá uma fronteira de decisão mais complexa e parecerá não-linear \n",
    "quando desenhado em um gráfico bidimensional. \n",
    "\n",
    "Embora o mapeamento de características nos permita construir um classificador mais expressivo, \n",
    "também é mais suscetível a sobreajuste (overfitting). Desse modo, será implementada a \n",
    "**_Regressão Logística Regularizada_** sobre os dados fornecidos e também verá como a regularização pode \n",
    "ajudar a combater o problema do sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_feature(X1, X2):\n",
    "    '''\n",
    "    Função que mapeia características p/ os termos polinomiais X1 e X2 até a 6ª potência.\n",
    "    Retorna um novo conjunto com mais características, através do algoritmo de mapping\n",
    "    X1, X2, X1 ** 2, X2 ** 2, X1*X2, X1*X2 ** 2, etc...\n",
    "    Os parâmetros X1, X2 devem ser do mesmo tamanho\n",
    "    '''\n",
    "    # Potência padrão para o mapeamento\n",
    "    potencia = 6\n",
    "    \n",
    "    X1.shape = (X1.size, 1)\n",
    "    X2.shape = (X2.size, 1)\n",
    "    \n",
    "    features = np.ones(shape=(X1.size, 1))\n",
    "\n",
    "    for i in range(1, potencia + 1):\n",
    "        for j in range(i + 1):\n",
    "            r = (X1 ** (i - j)) * (X2 ** j)\n",
    "            features = append(features, r, axis=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 0:2]\n",
    "y = data[:, 2]\n",
    "\n",
    "pos = where(y == 1)\n",
    "neg = where(y == 0)\n",
    "scatter(X[pos, 0], X[pos, 1], marker='o', c='b')\n",
    "scatter(X[neg, 0], X[neg, 1], marker='x', c='r')\n",
    "xlabel('Microchip Test 1')\n",
    "ylabel('Microchip Test 2')\n",
    "legend(['y = 1', 'y = 0'])\n",
    "\n",
    "\n",
    "m, n = X.shape\n",
    "y.shape = (m, 1)\n",
    "\n",
    "it = map_feature(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1         2         3         4         5             6   \\\n",
      "0    1.0  0.051267  0.699560  0.002628  0.035864  0.489384  1.347453e-04   \n",
      "1    1.0 -0.092742  0.684940  0.008601 -0.063523  0.469143 -7.976812e-04   \n",
      "2    1.0 -0.213710  0.692250  0.045672 -0.147941  0.479210 -9.760555e-03   \n",
      "3    1.0 -0.375000  0.502190  0.140625 -0.188321  0.252195 -5.273438e-02   \n",
      "4    1.0 -0.513250  0.465640  0.263426 -0.238990  0.216821 -1.352032e-01   \n",
      "5    1.0 -0.524770  0.209800  0.275384 -0.110097  0.044016 -1.445130e-01   \n",
      "6    1.0 -0.398040  0.034357  0.158436 -0.013675  0.001180 -6.306380e-02   \n",
      "7    1.0 -0.305880 -0.192250  0.093563  0.058805  0.036960 -2.861892e-02   \n",
      "8    1.0  0.016705 -0.404240  0.000279 -0.006753  0.163410  4.661648e-06   \n",
      "9    1.0  0.131910 -0.513890  0.017400 -0.067787  0.264083  2.295267e-03   \n",
      "10   1.0  0.385370 -0.565060  0.148510 -0.217757  0.319293  5.723131e-02   \n",
      "11   1.0  0.529380 -0.521200  0.280243 -0.275913  0.271649  1.483551e-01   \n",
      "12   1.0  0.638820 -0.243420  0.408091 -0.155502  0.059253  2.606967e-01   \n",
      "13   1.0  0.736750 -0.184940  0.542801 -0.136255  0.034203  3.999083e-01   \n",
      "14   1.0  0.546660  0.487570  0.298837  0.266535  0.237725  1.633623e-01   \n",
      "15   1.0  0.322000  0.582600  0.103684  0.187597  0.339423  3.338625e-02   \n",
      "16   1.0  0.166470  0.538740  0.027712  0.089684  0.290241  4.613260e-03   \n",
      "17   1.0 -0.046659  0.816520  0.002177 -0.038098  0.666705 -1.015795e-04   \n",
      "18   1.0 -0.173390  0.699560  0.030064 -0.121297  0.489384 -5.212813e-03   \n",
      "19   1.0 -0.478690  0.633770  0.229144 -0.303379  0.401664 -1.096890e-01   \n",
      "20   1.0 -0.605410  0.597220  0.366521 -0.361563  0.356672 -2.218956e-01   \n",
      "21   1.0 -0.628460  0.334060  0.394962 -0.209943  0.111596 -2.482178e-01   \n",
      "22   1.0 -0.593890  0.005117  0.352705 -0.003039  0.000026 -2.094682e-01   \n",
      "23   1.0 -0.421080 -0.272660  0.177308  0.114812  0.074343 -7.466101e-02   \n",
      "24   1.0 -0.115780 -0.396930  0.013405  0.045957  0.157553 -1.552032e-03   \n",
      "25   1.0  0.201040 -0.601610  0.040417 -0.120948  0.361935  8.125450e-03   \n",
      "26   1.0  0.466010 -0.535820  0.217165 -0.249697  0.287103  1.012012e-01   \n",
      "27   1.0  0.673390 -0.535820  0.453454 -0.360816  0.287103  3.053515e-01   \n",
      "28   1.0 -0.138820  0.546050  0.019271 -0.075803  0.298171 -2.675199e-03   \n",
      "29   1.0 -0.294350  0.779970  0.086642 -0.229584  0.608353 -2.550305e-02   \n",
      "..   ...       ...       ...       ...       ...       ...           ...   \n",
      "88   1.0 -0.403800  0.706870  0.163054 -0.285434  0.499665 -6.584138e-02   \n",
      "89   1.0 -0.380760  0.918860  0.144978 -0.349865  0.844304 -5.520189e-02   \n",
      "90   1.0 -0.507490  0.904240  0.257546 -0.458893  0.817650 -1.307021e-01   \n",
      "91   1.0 -0.547810  0.706870  0.300096 -0.387230  0.499665 -1.643955e-01   \n",
      "92   1.0  0.103110  0.779970  0.010632  0.080423  0.608353  1.096232e-03   \n",
      "93   1.0  0.057028  0.918860  0.003252  0.052401  0.844304  1.854661e-04   \n",
      "94   1.0 -0.104260  0.991960  0.010870 -0.103422  0.983985 -1.133322e-03   \n",
      "95   1.0 -0.081221  1.108900  0.006597 -0.090066  1.229659 -5.358028e-04   \n",
      "96   1.0  0.287440  1.087000  0.082622  0.312447  1.181569  2.374880e-02   \n",
      "97   1.0  0.396890  0.823830  0.157522  0.326970  0.678696  6.251878e-02   \n",
      "98   1.0  0.638820  0.889620  0.408091  0.568307  0.791424  2.606967e-01   \n",
      "99   1.0  0.823160  0.663010  0.677592  0.545763  0.439582  5.577669e-01   \n",
      "100  1.0  0.673390  0.641080  0.453454  0.431697  0.410984  3.053515e-01   \n",
      "101  1.0  1.070900  0.100150  1.146827  0.107251  0.010030  1.228137e+00   \n",
      "102  1.0 -0.046659 -0.579680  0.002177  0.027047  0.336029 -1.015795e-04   \n",
      "103  1.0 -0.236750 -0.638160  0.056051  0.151084  0.407248 -1.326997e-02   \n",
      "104  1.0 -0.150350 -0.367690  0.022605  0.055282  0.135196 -3.398680e-03   \n",
      "105  1.0 -0.490210 -0.301900  0.240306  0.147994  0.091144 -1.178003e-01   \n",
      "106  1.0 -0.467170 -0.133770  0.218248  0.062493  0.017894 -1.019588e-01   \n",
      "107  1.0 -0.288590 -0.060673  0.083284  0.017510  0.003681 -2.403498e-02   \n",
      "108  1.0 -0.611180 -0.067982  0.373541  0.041549  0.004622 -2.283008e-01   \n",
      "109  1.0 -0.663020 -0.214180  0.439596  0.142006  0.045873 -2.914606e-01   \n",
      "110  1.0 -0.599650 -0.418860  0.359580  0.251169  0.175444 -2.156222e-01   \n",
      "111  1.0 -0.726380 -0.082602  0.527628  0.060000  0.006823 -3.832584e-01   \n",
      "112  1.0 -0.830070  0.312130  0.689016 -0.259090  0.097425 -5.719317e-01   \n",
      "113  1.0 -0.720620  0.538740  0.519293 -0.388227  0.290241 -3.742131e-01   \n",
      "114  1.0 -0.593890  0.494880  0.352705 -0.293904  0.244906 -2.094682e-01   \n",
      "115  1.0 -0.484450  0.999270  0.234692 -0.484096  0.998541 -1.136964e-01   \n",
      "116  1.0 -0.006336  0.999270  0.000040 -0.006332  0.998541 -2.544062e-07   \n",
      "117  1.0  0.632650 -0.030612  0.400246 -0.019367  0.000937  2.532156e-01   \n",
      "\n",
      "           7         8             9       ...                 18  \\\n",
      "0    0.001839  0.025089  3.423536e-01      ...       8.998098e-04   \n",
      "1    0.005891 -0.043509  3.213347e-01      ...       2.763825e-03   \n",
      "2    0.031616 -0.102412  3.317332e-01      ...       1.515091e-02   \n",
      "3    0.070620 -0.094573  1.266497e-01      ...       1.781011e-02   \n",
      "4    0.122661 -0.111283  1.009603e-01      ...       2.659554e-02   \n",
      "5    0.057775 -0.023098  9.234565e-03      ...       2.543047e-03   \n",
      "6    0.005443 -0.000470  4.055512e-05      ...       6.425385e-06   \n",
      "7   -0.017987 -0.011305 -7.105572e-03      ...      -6.648156e-04   \n",
      "8   -0.000113  0.002730 -6.605685e-02      ...      -1.843363e-05   \n",
      "9   -0.008942  0.034835 -1.357096e-01      ...      -2.361380e-03   \n",
      "10  -0.083917  0.123046 -1.804196e-01      ...      -2.679412e-02   \n",
      "11  -0.146063  0.143806 -1.415837e-01      ...      -3.967786e-02   \n",
      "12  -0.099338  0.037852 -1.442344e-02      ...      -5.886075e-03   \n",
      "13  -0.100386  0.025199 -6.325466e-03      ...      -3.433467e-03   \n",
      "14   0.145704  0.129954  1.159073e-01      ...       3.463742e-02   \n",
      "15   0.060406  0.109294  1.977477e-01      ...       2.050327e-02   \n",
      "16   0.014930  0.048316  1.563643e-01      ...       4.333209e-03   \n",
      "17   0.001778 -0.031108  5.443779e-01      ...       1.185145e-03   \n",
      "18   0.021032 -0.084854  3.423536e-01      ...       1.029255e-02   \n",
      "19   0.145225 -0.192273  2.545629e-01      ...       5.833158e-02   \n",
      "20   0.218894 -0.215933  2.130115e-01      ...       7.807324e-02   \n",
      "21   0.131941 -0.070134  3.727979e-02      ...       1.472410e-02   \n",
      "22   0.001805 -0.000016  1.339819e-07      ...       4.725614e-08   \n",
      "23  -0.048345 -0.031305 -2.027049e-02      ...      -3.594128e-03   \n",
      "24  -0.005321 -0.018242 -6.253768e-02      ...      -8.383181e-04   \n",
      "25  -0.024315  0.072763 -2.177435e-01      ...      -8.800556e-03   \n",
      "26  -0.116362  0.133793 -1.538356e-01      ...      -3.340775e-02   \n",
      "27  -0.242970  0.193332 -1.538356e-01      ...      -6.975737e-02   \n",
      "28   0.010523 -0.041392  1.628161e-01      ...       3.137627e-03   \n",
      "29   0.067578 -0.179069  4.744972e-01      ...       4.111135e-02   \n",
      "..        ...       ...           ...      ...                ...   \n",
      "88   0.115258 -0.201765  3.531983e-01      ...       5.759056e-02   \n",
      "89   0.133215 -0.321477  7.757969e-01      ...       1.124736e-01   \n",
      "90   0.232883 -0.414949  7.393518e-01      ...       1.904172e-01   \n",
      "91   0.212129 -0.273722  3.531983e-01      ...       1.059933e-01   \n",
      "92   0.008292  0.062727  4.744972e-01      ...       5.044699e-03   \n",
      "93   0.002988  0.048149  7.757969e-01      ...       2.523041e-03   \n",
      "94   0.010783 -0.102590  9.760734e-01      ...       1.061006e-02   \n",
      "95   0.007315 -0.099874  1.363569e+00      ...       8.995262e-03   \n",
      "96   0.089810  0.339630  1.284366e+00      ...       1.061165e-01   \n",
      "97   0.129771  0.269368  5.591300e-01      ...       8.807510e-02   \n",
      "98   0.363046  0.505577  7.040664e-01      ...       2.873232e-01   \n",
      "99   0.449251  0.361847  2.914474e-01      ...       1.974826e-01   \n",
      "100  0.290700  0.276752  2.634733e-01      ...       1.194731e-01   \n",
      "101  0.114855  0.010741  1.004507e-03      ...       1.151995e-03   \n",
      "102 -0.001262 -0.015679 -1.947892e-01      ...      -4.240683e-04   \n",
      "103 -0.035769 -0.096416 -2.598895e-01      ...      -1.456695e-02   \n",
      "104 -0.008312 -0.020327 -4.971019e-02      ...      -1.123705e-03   \n",
      "105 -0.072548 -0.044680 -2.751626e-02      ...      -6.612317e-03   \n",
      "106 -0.029195 -0.008360 -2.393736e-03      ...      -5.224276e-04   \n",
      "107 -0.005053 -0.001062 -2.233502e-04      ...      -1.860154e-05   \n",
      "108 -0.025394 -0.002825 -3.141824e-04      ...      -1.173600e-04   \n",
      "109 -0.094153 -0.030415 -9.825095e-03      ...      -4.319068e-03   \n",
      "110 -0.150614 -0.105205 -7.348635e-02      ...      -2.642423e-02   \n",
      "111 -0.043583 -0.004956 -5.636009e-04      ...      -2.973716e-04   \n",
      "112  0.215063 -0.080870  3.040931e-02      ...       2.095251e-02   \n",
      "113  0.279764 -0.209153  1.563643e-01      ...       8.119893e-02   \n",
      "114  0.174547 -0.145447  1.211992e-01      ...       4.274760e-02   \n",
      "115  0.234520 -0.483743  9.978116e-01      ...       2.341782e-01   \n",
      "116  0.000040 -0.006327  9.978116e-01      ...       4.006210e-05   \n",
      "117 -0.012252  0.000593 -2.868634e-05      ...      -1.148159e-05   \n",
      "\n",
      "               19            20            21            22            23  \\\n",
      "0    1.227829e-02  1.675424e-01  1.815630e-08  2.477505e-07  3.380660e-06   \n",
      "1   -2.041205e-02  1.507518e-01  6.362953e-07 -4.699318e-06  3.470651e-05   \n",
      "2   -4.907685e-02  1.589699e-01  9.526844e-05 -3.085938e-04  9.995978e-04   \n",
      "3   -2.385083e-02  3.194040e-02  2.780914e-03 -3.724126e-03  4.987251e-03   \n",
      "4   -2.412849e-02  2.189028e-02  1.827990e-02 -1.658422e-02  1.504584e-02   \n",
      "5   -1.016696e-03  4.064690e-04  2.088401e-02 -8.349308e-03  3.338005e-03   \n",
      "6   -5.546100e-07  4.787141e-08  3.977043e-03 -3.432803e-04  2.963039e-05   \n",
      "7   -4.178462e-04 -2.626224e-04  8.190426e-04  5.147801e-04  3.235467e-04   \n",
      "8    4.460706e-04 -1.079435e-02  2.173096e-11 -5.258619e-10  1.272520e-08   \n",
      "9    9.199376e-03 -3.583858e-02  5.268249e-06 -2.052385e-05  7.995603e-05   \n",
      "10   3.928766e-02 -5.760668e-02  3.275423e-03 -4.802685e-03  7.042077e-03   \n",
      "11   3.906476e-02 -3.846113e-02  2.200925e-02 -2.166916e-02  2.133433e-02   \n",
      "12   2.242867e-03 -8.546362e-04  6.796276e-02 -2.589696e-02  9.867941e-03   \n",
      "13   8.618736e-04 -2.163487e-04  1.599267e-01 -4.014501e-02  1.007726e-02   \n",
      "14   3.089336e-02  2.755401e-02  2.668725e-02  2.380255e-02  2.122966e-02   \n",
      "15   3.709691e-02  6.712007e-02  1.114642e-03  2.016740e-03  3.648921e-03   \n",
      "16   1.402339e-02  4.538330e-02  2.128217e-05  6.887460e-05  2.228960e-04   \n",
      "17  -2.073971e-02  3.629394e-01  1.031840e-08 -1.805693e-07  3.159915e-06   \n",
      "18  -4.152637e-02  1.675424e-01  2.717342e-05 -1.096340e-04  4.423297e-04   \n",
      "19  -7.722912e-02  1.022488e-01  1.203168e-02 -1.592955e-02  2.109020e-02   \n",
      "20  -7.701706e-02  7.597518e-02  4.923768e-02 -4.857159e-02  4.791451e-02   \n",
      "21  -7.826643e-03  4.160278e-03  6.161208e-02 -3.275010e-02  1.740843e-02   \n",
      "22  -4.071624e-10  3.508141e-12  4.387691e-02 -3.780467e-04  3.257278e-06   \n",
      "23  -2.327289e-03 -1.506979e-03  5.574266e-03  3.609479e-03  2.337229e-03   \n",
      "24  -2.874016e-03 -9.853026e-03  2.408803e-06  8.258129e-06  2.831144e-05   \n",
      "25   2.633557e-02 -7.880889e-02  6.602294e-05 -1.975729e-04  5.912348e-04   \n",
      "26   3.841235e-02 -4.416666e-02  1.024169e-02 -1.177593e-02  1.354000e-02   \n",
      "27   5.550631e-02 -4.416666e-02  9.323951e-02 -7.419117e-02  5.903431e-02   \n",
      "28  -1.234189e-02  4.854696e-02  7.156691e-06 -2.815092e-05  1.107320e-04   \n",
      "29  -1.089371e-01  2.886619e-01  6.504056e-04 -1.723448e-03  4.566800e-03   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "88  -1.008149e-01  1.764809e-01  4.335088e-03 -7.588765e-03  1.328447e-02   \n",
      "89  -2.714243e-01  6.550082e-01  3.047249e-03 -7.353700e-03  1.774614e-02   \n",
      "90  -3.392832e-01  6.045310e-01  1.708303e-02 -3.043835e-02  5.423472e-02   \n",
      "91  -1.367692e-01  1.764809e-01  2.702587e-02 -3.487300e-02  4.499859e-02   \n",
      "92   3.816035e-02  2.886619e-01  1.201724e-06  9.090376e-06  6.876365e-05   \n",
      "93   4.065234e-02  6.550082e-01  3.439766e-08  5.542300e-07  8.929996e-06   \n",
      "94  -1.009472e-01  9.604412e-01  1.284418e-06 -1.222033e-05  1.162677e-04   \n",
      "95  -1.228112e-01  1.676725e+00  2.870847e-07 -3.919530e-06  5.351285e-05   \n",
      "96   4.012965e-01  1.517566e+00  5.640054e-04  2.132876e-03  8.065808e-03   \n",
      "97   1.828187e-01  3.794792e-01  3.908597e-03  8.113129e-03  1.684053e-02   \n",
      "98   4.001259e-01  5.572149e-01  6.796276e-02  9.464487e-02  1.318023e-01   \n",
      "99   1.590613e-01  1.281151e-01  3.111040e-01  2.505771e-01  2.018260e-01   \n",
      "100  1.137406e-01  1.082832e-01  9.323951e-02  8.876577e-02  8.450669e-02   \n",
      "101  1.077340e-04  1.007523e-05  1.508320e+00  1.410573e-01  1.319160e-02   \n",
      "102 -5.268521e-03 -6.545481e-02  1.031840e-08  1.281933e-07  1.592643e-06   \n",
      "103 -3.926524e-02 -1.058395e-01  1.760921e-04  4.746566e-04  1.279438e-03   \n",
      "104 -2.748088e-03 -6.720616e-03  1.155103e-05  2.824873e-05  6.908398e-05   \n",
      "105 -4.072252e-03 -2.507931e-03  1.387692e-02  8.546218e-03  5.263261e-03   \n",
      "106 -1.495925e-04 -4.283449e-05  1.039560e-02  2.976689e-03  8.523486e-04   \n",
      "107 -3.910778e-06 -8.221998e-07  5.776804e-04  1.214512e-04  2.553384e-05   \n",
      "108 -1.305404e-05 -1.452010e-06  5.212125e-02  5.797485e-03  6.448585e-04   \n",
      "109 -1.395219e-03 -4.507073e-04  8.494929e-02  2.744177e-02  8.864706e-03   \n",
      "110 -1.845752e-02 -1.289272e-02  4.649294e-02  3.247567e-02  2.268450e-02   \n",
      "111 -3.381630e-05 -3.845500e-06  1.468870e-01  1.670360e-02  1.899488e-03   \n",
      "112 -7.878740e-03  2.962631e-03  3.271058e-01 -1.230011e-01  4.625193e-02   \n",
      "113 -6.070482e-02  4.538330e-02  1.400354e-01 -1.046913e-01  7.826790e-02   \n",
      "114 -3.562096e-02  2.968243e-02  4.387691e-02 -3.656200e-02  3.046659e-02   \n",
      "115 -4.830370e-01  9.963553e-01  1.292688e-02 -2.666414e-02  5.499985e-02   \n",
      "116 -6.317918e-03  9.963553e-01  6.472253e-14 -1.020695e-11  1.609667e-09   \n",
      "117  5.555592e-07 -2.688181e-08  6.411816e-02 -3.102482e-03  1.501196e-04   \n",
      "\n",
      "               24            25            26            27  \n",
      "0    4.613055e-05  6.294709e-04  8.589398e-03  1.172060e-01  \n",
      "1   -2.563226e-04  1.893054e-03 -1.398103e-02  1.032560e-01  \n",
      "2   -3.237900e-03  1.048821e-02 -3.397345e-02  1.100469e-01  \n",
      "3   -6.678793e-03  8.944062e-03 -1.197765e-02  1.604015e-02  \n",
      "4   -1.365016e-02  1.238395e-02 -1.123519e-02  1.019299e-02  \n",
      "5   -1.334515e-03  5.335313e-04 -2.133027e-04  8.527719e-05  \n",
      "6   -2.557560e-06  2.207569e-07 -1.905473e-08  1.644718e-09  \n",
      "7    2.033538e-04  1.278108e-04  8.033094e-05  5.048915e-05  \n",
      "8   -3.079338e-07  7.451610e-06 -1.803196e-04  4.363507e-03  \n",
      "9   -3.114897e-04  1.213490e-03 -4.727468e-03  1.841709e-02  \n",
      "10  -1.032565e-02  1.514029e-02 -2.219989e-02  3.255123e-02  \n",
      "11  -2.100467e-02  2.068010e-02 -2.036055e-02  2.004594e-02  \n",
      "12  -3.760142e-03  1.432788e-03 -5.459587e-04  2.080355e-04  \n",
      "13  -2.529607e-03  6.349853e-04 -1.593949e-04  4.001153e-05  \n",
      "14   1.893489e-02  1.688817e-02  1.506268e-02  1.343451e-02  \n",
      "15   6.602054e-03  1.194521e-02  2.161266e-02  3.910415e-02  \n",
      "16   7.213493e-04  2.334473e-03  7.554959e-03  2.444980e-02  \n",
      "17  -5.529766e-05  9.676943e-04 -1.693439e-02  2.963473e-01  \n",
      "18  -1.784625e-03  7.200257e-03 -2.905018e-02  1.172060e-01  \n",
      "19  -2.792274e-02  3.696881e-02 -4.894550e-02  6.480225e-02  \n",
      "20  -4.726632e-02  4.662690e-02 -4.599613e-02  4.537389e-02  \n",
      "21  -9.253507e-03  4.918732e-03 -2.614569e-03  1.389783e-03  \n",
      "22  -2.806495e-08  2.418097e-10 -2.083450e-12  1.795116e-14  \n",
      "23   1.513415e-03  9.799749e-04  6.345586e-04  4.108928e-04  \n",
      "24   9.706047e-05  3.327536e-04  1.140783e-03  3.910962e-03  \n",
      "25  -1.769264e-03  5.294502e-03 -1.584374e-02  4.741222e-02  \n",
      "26  -1.556835e-02  1.790054e-02 -2.058211e-02  2.366538e-02  \n",
      "27  -4.697391e-02  3.737739e-02 -2.974139e-02  2.366538e-02  \n",
      "28  -4.355654e-04  1.713301e-03 -6.739289e-03  2.650907e-02  \n",
      "29  -1.210113e-02  3.206562e-02 -8.496764e-02  2.251476e-01  \n",
      "..            ...           ...           ...           ...  \n",
      "88  -2.325507e-02  4.070904e-02 -7.126299e-02  1.247491e-01  \n",
      "89  -4.282546e-02  1.033475e-01 -2.494009e-01  6.018608e-01  \n",
      "90  -9.663481e-02  1.721828e-01 -3.067934e-01  5.466411e-01  \n",
      "91  -5.806421e-02  7.492351e-02 -9.667801e-02  1.247491e-01  \n",
      "92   5.201589e-04  3.934714e-03  2.976393e-02  2.251476e-01  \n",
      "93   1.438840e-04  2.318322e-03  3.735381e-02  6.018608e-01  \n",
      "94  -1.106205e-03  1.052476e-02 -1.001356e-01  9.527193e-01  \n",
      "95  -7.306042e-04  9.974846e-03 -1.361853e-01  1.859321e+00  \n",
      "96   3.050214e-02  1.153487e-01  4.362093e-01  1.649595e+00  \n",
      "97   3.495612e-02  7.255891e-02  1.506115e-01  3.126264e-01  \n",
      "98   1.835478e-01  2.556084e-01  3.559600e-01  4.957095e-01  \n",
      "99   1.625597e-01  1.309329e-01  1.054592e-01  8.494161e-02  \n",
      "100  8.045197e-02  7.659179e-02  7.291683e-02  6.941820e-02  \n",
      "101  1.233672e-03  1.153723e-04  1.078956e-05  1.009034e-06  \n",
      "102  1.978660e-05  2.458239e-04  3.054056e-03  3.794285e-02  \n",
      "103  3.448726e-03  9.296047e-03  2.505751e-02  6.754255e-02  \n",
      "104  1.689490e-04  4.131751e-04  1.010445e-03  2.471103e-03  \n",
      "105  3.241424e-03  1.996259e-03  1.229413e-03  7.571443e-04  \n",
      "106  2.440625e-04  6.988513e-05  2.001099e-05  5.729970e-06  \n",
      "107  5.368219e-06  1.128611e-06  2.372786e-07  4.988533e-08  \n",
      "108  7.172808e-05  7.978367e-06  8.874396e-07  9.871056e-08  \n",
      "109  2.863628e-03  9.250579e-04  2.988279e-04  9.653248e-05  \n",
      "110  1.584529e-02  1.106805e-02  7.731118e-03  5.400243e-03  \n",
      "111  2.160048e-04  2.456349e-05  2.793294e-06  3.176460e-07  \n",
      "112 -1.739205e-02  6.539906e-03 -2.459191e-03  9.247260e-04  \n",
      "113 -5.851357e-02  4.374511e-02 -3.270412e-02  2.444980e-02  \n",
      "114 -2.538737e-02  2.115493e-02 -1.762810e-02  1.468924e-02  \n",
      "115 -1.134476e-01  2.340073e-01 -4.826843e-01  9.956280e-01  \n",
      "116 -2.538495e-07  4.003286e-05 -6.313306e-03  9.956280e-01  \n",
      "117 -7.263830e-06  3.514745e-07 -1.700678e-08  8.229060e-10  \n",
      "\n",
      "[118 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Função de custo e gradiente\n",
    "\n",
    "Agora, você deverá implementar o código para calcular **_a função de custo e\n",
    "o gradiente para a regressão logística regularizada_**. Crie um arquivo de nome\n",
    "costFunctionReg.py que contém uma função de nome costFunctionReg.py\n",
    "e que computa o custo e o gradiente. Lembre-se de que a função de custo\n",
    "regularizada na regressão logística é dada por:\n",
    "    \n",
    "$$J_{regularizado} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(x^{(i)}\\right) + (1-y^{(i)})\\log\\left(1- x^{(i)}\\right) \\large{)} }_\\text{Função de Custo} + \\underbrace{\\frac{\\lambda}{2m} \\sum\\limits_{j = 1}^{n}\\ {\\theta}_{j}^{2} }_\\text{Fator Regularização} $$\n",
    "    \n",
    "Depois de concluir a implementação da função **costFunctionReg**, você deve\n",
    "testar a corretude dela usando o valor inicial de ${\\theta}$ (inicializado todo com zeros).\n",
    "Você deve ver que o custo é de cerca de `0.693`.\n",
    "Porém, usando a função **costFunctionReg**, você agora deve computar os valores ótimos para ${\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt, where, zeros, e, array, log, ones, append, linspace\n",
    "from pylab import scatter, show, legend, xlabel, ylabel, contour, title\n",
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "\n",
    "def sigmoid(X):\n",
    "    '''Compute the sigmoid function '''\n",
    "    #d = zeros(shape=(X.shape))\n",
    "\n",
    "    den = 1.0 + e ** (-1.0 * X)\n",
    "\n",
    "    d = 1.0 / den\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def cost_function_reg(theta, X, y, l):\n",
    "    '''Compute the cost and partial derivatives as grads\n",
    "    '''\n",
    "\n",
    "    h = sigmoid(X.dot(theta))\n",
    "\n",
    "    thetaR = theta[1:, 0]\n",
    "\n",
    "    J = (1.0 / m) * ((-y.T.dot(log(h))) - ((1 - y.T).dot(log(1.0 - h)))) + (l / (2.0 * m)) * (thetaR.T.dot(thetaR))\n",
    "\n",
    "    delta = h - y\n",
    "    sumdelta = delta.T.dot(X[:, 1])\n",
    "    grad1 = (1.0 / m) * sumdelta\n",
    "\n",
    "    XR = X[:, 1:X.shape[1]]\n",
    "    sumdelta = delta.T.dot(XR)\n",
    "\n",
    "    grad = (1.0 / m) * (sumdelta + l * thetaR)\n",
    "\n",
    "    out = zeros(shape=(grad.shape[0], grad.shape[1] + 1))\n",
    "\n",
    "    out[:, 0] = grad1\n",
    "    out[:, 1:] = grad\n",
    "\n",
    "    return J.flatten(), out.T.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Testando a Função de Custo e o Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.69314718]),\n",
       " array([  1.87880932e-02,   1.87880932e-02,   7.77711864e-05,\n",
       "          5.03446395e-02,   1.15013308e-02,   3.76648474e-02,\n",
       "          1.83559872e-02,   7.32393391e-03,   8.19244468e-03,\n",
       "          2.34764889e-02,   3.93486234e-02,   2.23923907e-03,\n",
       "          1.28600503e-02,   3.09593720e-03,   3.93028171e-02,\n",
       "          1.99707467e-02,   4.32983232e-03,   3.38643902e-03,\n",
       "          5.83822078e-03,   4.47629067e-03,   3.10079849e-02,\n",
       "          3.10312442e-02,   1.09740238e-03,   6.31570797e-03,\n",
       "          4.08503006e-04,   7.26504316e-03,   1.37646175e-03,\n",
       "          3.87936363e-02]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "m, n = X.shape\n",
    "y.shape = (m, 1)\n",
    "it = map_feature(X[:, 0], X[:, 1])\n",
    "\n",
    "#Initialize theta parameters\n",
    "initial_theta = zeros(shape=(it.shape[1], 1))\n",
    "\n",
    "#Set regularization parameter lambda to 1\n",
    "regularizacao = 1\n",
    "\n",
    "# Compute and display initial cost and gradient for regularized logistic regression\n",
    "cost, grad = cost_function_reg(initial_theta, it, y, regularizacao)\n",
    "\n",
    "#def decorated_cost(theta):\n",
    "#    return cost_function_reg(theta, it, y, l)\n",
    "\n",
    "#cost_function_reg(theta, it, y, l)\n",
    "\n",
    "#print fmin_bfgs(decorated_cost, initial_theta, args=(it, y, l), maxfun=400)\n",
    "\n",
    "cost, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Esboço da fronteira de decisão\n",
    "\n",
    "Nessa parte, você deve esboçar (plotar) a fronteira de decisão que foi aprendida\n",
    "para separar os exemplos positivos dos negativos. Crie uma arquivo de nome\n",
    "**``plotDecisionBoundary.py``**, para criar esse gráfico que traça o limite da decisão\n",
    "não-linear. Seu gráfico deve ser semelhante ao apresentado na **_Figura_** abaixo.\n",
    "\n",
    "![ScatterBoundaryPlot](scatter_boundary.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-59a0f178f678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lambda = %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Microchip Test 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mcontour\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2851\u001b[0m                       mplDeprecation)\n\u001b[1;32m   2852\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2853\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2854\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mcontour\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5823\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5824\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filled'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5825\u001b[0;31m         \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcontour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuadContourSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/matplotlib/contour.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/matplotlib/contour.py\u001b[0m in \u001b[0;36m_process_levels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# The following attributes are no longer needed, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# should be deprecated and removed to reduce confusion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m     return _methods._amin(a, axis=axis,\n\u001b[0;32m-> 2352\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "#Plot Boundary\n",
    "m, n = X.shape\n",
    "y.shape = (m, 1)\n",
    "it = map_feature(X[:, 0], X[:, 1])\n",
    "theta = zeros(shape=(it.shape[1], 1))\n",
    "\n",
    "u = linspace(-1, 1.5, 50)\n",
    "v = linspace(-1, 1.5, 50)\n",
    "z = zeros(shape=(len(u), len(v)))\n",
    "for i in range(len(u)):\n",
    "    for j in range(len(v)):\n",
    "        z[i, j] = (map_feature(array(u[i]), array(v[j])).dot(array(theta)))\n",
    "\n",
    "z = z.T\n",
    "contour(u, v, z)\n",
    "title('lambda = %f' % l)\n",
    "xlabel('Microchip Test 1')\n",
    "ylabel('Microchip Test 2')\n",
    "legend(['y = 1', 'y = 0', 'Decision boundary'])\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-07b6553796d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Make theta a 1-d array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    '''Predict whether the label\n",
    "    is 0 or 1 using learned logistic\n",
    "    regression parameters '''\n",
    "    m, n = X.shape\n",
    "    p = zeros(shape=(m, 1))\n",
    "\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    for it in range(0, h.shape[0]):\n",
    "        if h[it] > 0.5:\n",
    "            p[it, 0] = 1\n",
    "        else:\n",
    "            p[it, 0] = 0\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "#% Compute accuracy on our training set\n",
    "p = predict(array(theta), it)\n",
    "print 'Train Accuracy: %f' % ((y[where(p == y)].size / float(y.size)) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.3 Visualização de J(ø)\n",
    "\n",
    "Para melhor entender a função de custo, você irá nessa parte do trabalho plotar o custo sobre \n",
    "uma grade bidimensional de valores de 0 e de 1. Para isso, você deve usar sua implementação da função **computarCusto**.\n",
    "\n",
    "O código que você deve implementar deve gerar um array bidimensional de valores de J(ø). Os valores gerados pelo seu código devem estar na faixa a seguir: -10;0;+10 e -1;+4. Utilize incremento de 0.01 para gerar os valores de 0 e de 1.\n",
    "\n",
    "A seguir, usando a função _matplotlib.pyplot.contour_ da biblioteca matplotlib, produza um gráfico de curvas de contorno (contour plot). Também\n",
    "utilizando a biblioteca matplotlib, crie um gráfico da superfície correspondente a J(ø)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adicionando uma coluna de 1's em X p/ X de teste\n",
    "X_teste = np.ones(shape=(m, 2))\n",
    "X_teste[:, 1] = X\n",
    "\n",
    "# Construindo a superfície para representar J(ø)\n",
    "theta0 = np.linspace(-10, 10, 100) # Intervalo para theta0 (-10;10)\n",
    "theta1 = np.linspace(-1, 4, 100)   # Intervalo para theta1 (-1;4)\n",
    "\n",
    "# Inicializando J(ø) com uma matriz de zeros\n",
    "J = np.zeros(shape=(theta0.size, theta1.size))\n",
    "\n",
    "# Preenchendo a matriz J\n",
    "for t1, element1 in enumerate(theta0):\n",
    "    for t2, element2 in enumerate(theta1):\n",
    "        thetaT = np.zeros(shape=(2, 1))\n",
    "        thetaT[0][0] = element1\n",
    "        thetaT[1][0] = element2\n",
    "        J[t1, t2] = computarCusto(X_teste, y, thetaT)\n",
    "\n",
    "# Plotando a Superfície de Contorno correspondente a J(ø)\n",
    "plt.contour(theta0, theta1, J.T, np.logspace(-4, 5, 50))\n",
    "plt.title('Gráfico da Superfície J(ø)')\n",
    "xlabel('Theta0')\n",
    "ylabel('Theta1')\n",
    "plt.scatter(theta[0][0], theta[1][0])\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regressão Linear com Múltiplas Variáveis\n",
    "\n",
    "\n",
    "Nessa parte do trabalho, você irá implementar a regressão linear com múltiplas variáveis para predizer \n",
    "o preço de venda de imóveis. O arquivo ex1data2.txt contém informações acerca de preços de imóveis. \n",
    "A primeira coluna corersponde ao tamanho do imóvel (em _pés quadrados_). A segunda coluna corresponde à\n",
    "quantidade de dormitórios no imóvel em questão. A terceira coluna corresponde ao preço do imóvel.\n",
    "\n",
    "## Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carregando o dataset na forma de txt, porque tem melhor desempenho p/ representação gráfica e \n",
    "# principalmente na vertorização, se comparado ao Dataframe, utilizado na primeira seção deste trabalho.\n",
    "\n",
    "data = np.loadtxt('am-T1-dados/ex1data2.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inicializando visualização gráfica\n",
    "plano = plt.figure()\n",
    "plano = plano.add_subplot(111, projection='3d')\n",
    "\n",
    "# Criação dos pontos ('x' vermelhos) para o gráfico\n",
    "for c, m in [('red', 'x')]:\n",
    "    tamanho = data[:, 0] \n",
    "    quartos = data[:, 1] \n",
    "    valor   = data[:, 2] \n",
    "    plano.scatter(tamanho, quartos, valor, c=c, marker=m)\n",
    "\n",
    "\n",
    "# Plotando o Gráfico\n",
    "plano.set_xlabel('Tamanho')\n",
    "plano.set_ylabel('Nº de Quartos')\n",
    "plano.set_zlabel('Valor do Imóvel')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1 Normalização das características\n",
    "\n",
    "Se você inspecionar os valores do conjunto de dados fornecido, irá notar que os tamanhos dos imóveis são \n",
    "aproximadamente 1000 vezes maiores que as quantidades encontradas na coluna de quantidade de dormitórios. \n",
    "Sua tarefa nessa parte é implementar uma função denominada normalizarCaracteristica em um arquivo denominado \n",
    "normalizarCaracteristica.py. Essa função deve:\n",
    "\n",
    " - subtrair o valor médio de todas as características do conjunto de dados.\n",
    " - após subtrair a média, dividir cada característica pelos seus respectivos desvios padrões.\n",
    "\n",
    "A sua função **normalizarCaracteristica** deve a matriz de dados X de dados como parâmetro (na forma de um numpy array). Além disso, essa função deve funcionar com conjuntos de dados de variados tamanhos (qualquer quantidade\n",
    "de características / exemplos). Repare que cada coluna da matriz de dados X passada para a função **normalizarCaracteristica** deve corresponder a um característica.\n",
    "\n",
    "**Nota de Implementação**: Ao normalizar as características, é importante armazenar os valores utilizados para a normalização - o valor médio e o desvio padrão utilizados para a normalização. Depois de aprender os parâmetros do modelo, muitas vezes queremos prever os preços das casas que não temos visto antes. Dado um novo valor x (área da sala de estar e número de quartos), devemos normalizar x usando a média e o desvio padrão que nós previamente\n",
    "calculamos a partir do conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizarCaracteristica(X):\n",
    "    '''\n",
    "    Retorna uma versão normalizada de X onde o valor médio de cada característica é 0 \n",
    "    e o desvio padrão é 1. Este é frequentemente um bom passo de pré-processamento \n",
    "    a ser feito ao trabalhar com algoritmos de aprendizado.\n",
    "    '''\n",
    "    valormedio = []\n",
    "    desviopadrao = []\n",
    "    X_Normalizado = X\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        m = np.mean(X[:, i])\n",
    "        s = np.std(X[:, i])\n",
    "        valormedio.append(m)\n",
    "        desviopadrao.append(s)\n",
    "        X_Normalizado[:, i] = (X_Normalizado[:, i] - m) / s\n",
    "\n",
    "    return X_Normalizado, valormedio, desviopadrao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Gradiente descendente\n",
    "\n",
    "Anteriormente, você implementou o GD em uma regressão linear univariada. A única diferença agora é que há mais uma característica na matriz de dados X. A função de hipótese h(x) e a atualização dos gradientes em lote permanecem inalteradas. Você deve implementar código nos arquivos denominados **computarCustoMulti.py** e **gdmulti.py** para implementar a função de custo e o algoritmo GD para regressão linear com múltiplas variáveis, respectivamente. Se o seu código na parte anterior (variável única) já provê suporte a múltiplas variáveis, você também pode reusá-lo aqui. Se assegure de que o seu código dá suporte a qualquer número de características e está bem vetorizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computarCustoMulti(X, y, theta):\n",
    "    '''\n",
    "    Função que computa o custo para Regressão Linear com múltiplas variáveis.\n",
    "    '''\n",
    "    # Número do conjunto de treinamento\n",
    "    m = y.size\n",
    "    J = (1 / (2 * m)) * (X.dot(theta) - y).T.dot(X.dot(theta) - y)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradienteDescendenteMulti(X, y, theta, alpha, iteracoes):\n",
    "    '''\n",
    "    Essa função calcula o gradiente descendente conforme o Theta, e com\n",
    "    etapas de iteracoes gradiente mediante a taxa de aprendizado em Alpha.\n",
    "    '''\n",
    "    m = y.size\n",
    "    J = np.zeros(shape=(iteracoes, 1))\n",
    "\n",
    "    for i in range(iteracoes):\n",
    "        hipotese = X.dot(theta)\n",
    "        \n",
    "        for it in range(theta.size):\n",
    "            temp = X[:, it]\n",
    "            temp.shape = (m, 1)\n",
    "\n",
    "            errors_x1 = (hipotese - y) * temp\n",
    "            theta[it][0] = theta[it][0] - alpha * (1.0 / m) * errors_x1.sum()\n",
    "\n",
    "        J[i, 0] = computarCustoMulti(X, y, theta)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "\n",
    "# Tamanho do conjunto de treinamento\n",
    "m = y.size\n",
    "y.shape = (m,1)\n",
    "\n",
    "# Normalizando X, obtendo Média e Desvio-padrão\n",
    "x, media, desviopadrao = normalizarCaracteristica(X)\n",
    "\n",
    "# Adicionando uma coluna de 1's ao novo X\n",
    "Xnovo = np.ones(shape=(m, 3))\n",
    "Xnovo[:, 1:3] = x\n",
    "\n",
    "# Atributos para a função GradienteDescendenteMulti\n",
    "iteracao = 100           # Número de repeticões p/ o algoritmo\n",
    "alpha = 0.01             # Taxa de aprendizado\n",
    "\n",
    "# Inicializando o Theta p/ execução da função GradienteDescendenteMulti\n",
    "theta = np.zeros(shape=(3, 1))\n",
    "J = gradienteDescendenteMulti(Xnovo, y, theta, alpha, iteracao)\n",
    "\n",
    "plot(np.arange(iteracao), J)\n",
    "xlabel('Iteracões')\n",
    "ylabel('Função de Custo')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regressão Logística\n",
    "\n",
    "Nessa parte do trabalho, você irá implementar a regressão logística. Em particular,\n",
    "você irá criar uma classificador para predizer se um estudante será admitido em uma \n",
    "universidade, com base nos resultados de duas avaliações. Suponha que estão disponíveis \n",
    "dados históricos acerca de realizações passadas dessas avaliações, e que esses dados \n",
    "históricos podem ser usados como conjunto de treinamento. Para cada exemplo desse conjunto \n",
    "de treinamento, temos as notas das duas avaliações e a decisão acerca do candidato \n",
    "(aprovado ou reprovado). \n",
    "\n",
    "Sua tarefa é construir um modelo de classificação que provê uma estimativa da probabilidade \n",
    "de admissão de um candidato, com base na notas que ele obteve nas duas avaliações. \n",
    "\n",
    "O arquivo **ex2data1.txt** contém os dados a serem usados nessa parte do trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Visualização dos dados\n",
    "\n",
    "Antes de começar a implementar qualquer algoritmo de aprendizado, é adequado\n",
    "visualizar os dados, quando possível. Nessa parte do trabalho, você deve\n",
    "carregar o arquivo com o conjunto de treinamento e plotar (i.e., produzir um\n",
    "gráfico) os pontos de dados. O resultado dessa tarefa deve ser um gráfico similar\n",
    "ao apresentado na _Figura_ abaixo.\n",
    "\n",
    "![Boundary.png](Boundary.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carregando os dados \n",
    "data = np.loadtxt('am-T1-dados/ex2data1.txt', delimiter=',', usecols=(0,1,2), unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transportando matriz\n",
    "X = np.transpose(np.array(data[:2]))\n",
    "y = np.transpose(np.array(data[2:]))\n",
    "\n",
    "# Tamanho do conjunto de treinamento\n",
    "m = y.size\n",
    "\n",
    "# Adicionando uma coluna de 1's ao novo X\n",
    "X = np.insert(X,0,1,axis=1)\n",
    "\n",
    "# Classificando a amostra em Positiva (data[:, 2]=1) e Negativa(data[:, 2]=0)\n",
    "X_Admitted  = np.array([X[i] for i in range(X.shape[0]) if y[i] == 1])\n",
    "X_Nadmitted = np.array([X[i] for i in range(X.shape[0]) if y[i] == 0])\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(X_Admitted[:, 1], X_Admitted[:, 2],'k+',label='Admitted')\n",
    "plt.plot(X_Nadmitted[:, 1], X_Nadmitted[:, 2],'yo',label='Not admitted')\n",
    "plt.title('Gráfico Decision Boundary p/ admissão de candidato', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Exam 1 Score', fontweight='bold')\n",
    "plt.ylabel('Exam 2 Score', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(False)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Implementação\n",
    "\n",
    "### 3.2.1 Função sigmoide\n",
    "\n",
    "Como primeiro passo nessa parte, implemente a função em Python que calcula\n",
    "o valor da função **sigmoide**. Defina essa função em um arquivo denominado\n",
    "**_sigmoide.py_**, de tal forma que ela possa ser chamada de outras parte do seu\n",
    "código. Após finalizar sua implementação, você pode verificar sua corretude:\n",
    "\n",
    " - Para a sigmoide(0), o valor retornado deve ser 0.5. \n",
    " - Para valores muito grandes positivos (ou negativos), ela retornará um valor muito próximo de 1 (ou de 0). \n",
    "\n",
    "O seu código também deve funcionar com vetores (i.e., **o seu código deve estar vetorizado**). Em particular, se\n",
    "uma matriz for passada, o seu código deve aplicar a função sigmoide a cada componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    A função sigmoid\n",
    "    '''\n",
    "    g = np.array([x]).flatten()\n",
    "    s = 1 / (1 + np.exp(-g))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\t ###########################  Teste para função sigmoid(0)  ###########################\\n')\n",
    "print('\\t O Valor da Sigmoid(0) é', sigmoid(0))\n",
    "print('\\t O Valor da Sigmoid([0,1,2,3000]) é', sigmoid(np.array([0,1,2,3000])))\n",
    "print('\\t ######################################################################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exibindo o gráfico da função Sigmoid\n",
    "X_teste = np.arange(-6,6,.5)\n",
    "plt.plot(X_teste, sigmoid(X_teste))\n",
    "plt.title(\"Função Sigmoid\", fontsize=18, fontweight='bold')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Função de custo e gradiente\n",
    "\n",
    "Agora, você deverá implementar a função de custo para a regressão logística.\n",
    "Essa função deve retornar o valor de função de custo e o gradiente. Implemente\n",
    "esse código em um arquivo denominado funcaoCustoRegressaoLogistica.py.\n",
    "Lembre-se de que o gradiente é um vetor com o mesmo número de elementos que ø.\n",
    "\n",
    "Uma vez que tenha implementado essa função, realize uma chamada usando\n",
    "o valor inicial de ø. Você deve confirmar que o valor produzido é aproximadamente 0.693."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custoJ(theta, X, y):\n",
    "    '''\n",
    "    A função custoJ retorna o valor de função de custo:\n",
    "        X é uma matrix com n-colunas e m-linhas\n",
    "        y é um vetor com m-linhas\n",
    "        theta é um vetor n-dimensional\n",
    "        \n",
    "    Obs.: Será utilizada para facilitar o cálculo de minimização. \n",
    "    '''\n",
    "    m = len(y)\n",
    "    H = sigmoid(X.dot(theta).T)\n",
    "    J = -np.sum( y* np.log(H) + (1-y) * np.log(1-H))/m\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custoRegressaoLogistica(theta, X, y):\n",
    "    '''\n",
    "    A função funcaoCustoRegressaoLogistica retorna o valor de função de custo e o gradiente.\n",
    "        Returna J, gradiente:\n",
    "        \n",
    "        X é uma matrix com n-colunas e m-linhas\n",
    "        y é um vetor com m-linhas\n",
    "        theta é um vetor n-dimensional\n",
    "    '''\n",
    "    \n",
    "    # Calcula o Custo\n",
    "    m = len(y)\n",
    "    H = sigmoid(X.dot(theta).T)\n",
    "    J = -np.sum( y* np.log(H) + (1-y) * np.log(1-H))/m\n",
    "\n",
    "    # Calcula o Gradiente\n",
    "    erro = H-y\n",
    "    gradiente = []\n",
    "    for i in range(len(X.columns)):\n",
    "        gradiente.append(np.sum(erro*(X.iloc[:,i]))/m)\n",
    "    \n",
    "    return J, gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Aprendizado dos parâmetros\n",
    "\n",
    "Para a regressão logística, o objetivo é minimizar J(ø) com relação ao vetor\n",
    "de parâmetros ø. Sendo assim, nessa parte você deve implementar uma função\n",
    "em Python para encontrar o vetor ø que minimiza a função de custo. Utilize a\n",
    "função **funcaoCustoRegressaoLogistica** que você implementou previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def minimizar(theta, X, y):\n",
    "    '''\n",
    "    A função minimizar J(ø) com relação ao vetor de parâmetros ø\n",
    "    '''\n",
    "    minimo = optimize.fmin(func=custoJ, x0=theta, args=(X, y), maxiter=1000, full_output=True)\n",
    "    return minimo[0], minimo[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizando uma segunda estrutura de dados\n",
    "df = pd.read_csv('am-T1-dados/ex2data1.txt', names=['Exame1', 'Exame2', 'Admissao'])\n",
    "\n",
    "X = df.iloc[:, :2]\n",
    "y = df.iloc[:, 2]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add a column of ones to the feature matrix X to account for theta 0\n",
    "m = len(y)\n",
    "X.insert(0, \"theta0\",value=pd.Series(np.ones([m])))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apresentando uma visualização gráfica com base na classificação\n",
    "from seaborn import lmplot\n",
    "\n",
    "g = lmplot(\"Exame1\", \"Exame2\", hue=\"Admissao\", data=df, fit_reg=True, palette = \"dark\", markers = [\"o\",\"x\"], legend = True)\n",
    "plt.xlabel(\"Exame 1 Score\")\n",
    "plt.ylabel(\"Exame 2 Score\")\n",
    "plot_x = np.array([min(X.iloc[:,2])-2,  max(X.iloc[:,2])+2])\n",
    "plt.ylim(30,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta0 = np.zeros([X.shape[1], 1])\n",
    "hypothesis = sigmoid(X.dot(theta0).T)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(custoRegressaoLogistica(theta0, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "print(custoJ(theta0, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avaliando a minimização\n",
    "X_min, theta_min = minimizar(theta0, X, y)\n",
    "print(X_min, theta_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Avaliação do modelo\n",
    "\n",
    "Após o aprendizado dos parâmetros, você pode usar o modelo correspondente\n",
    "para predizer se um candidato qualquer será aprovado. Para um candidato\n",
    "com **_notas 45 e 85 na primeira e segunda avaliações_**, respectivamente, você deve\n",
    "esperar que ele seja aprovado com **probabilidade de 77.6%**.\n",
    "\n",
    "Outro modo de avaliar a qualidade dos parâmetros é verificar o quão bem o\n",
    "modelo aprendido prediz os pontos de dados do conjunto de treinamento. Nessa\n",
    "parte, você deve implementar uma função denominada predizer. Essa função\n",
    "deve produzir os valores 0 ou 1, dados um exemplo do conjunto de treinamento\n",
    "o vetor de parâmetros ø. Use essa função para produzir a porcentagem de\n",
    "acertos do seu classificador sobre o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predizer(theta, X):\n",
    "    P = sigmoid(X.dot(theta))\n",
    "    return (P >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predição de Admissão do candidato\n",
    "A = np.array([1,45,85])\n",
    "H = sigmoid(A.dot(X_min))\n",
    "\n",
    "# Efetuando predição p/ Admissão de um candidato com notas 45 e 85 na primeira e segunda avaliações \n",
    "print('\\t ######################################  ALUNO TESTE  #################################\\n')\n",
    "print('\\t Para as notas 45 e 85 no 1º e 2º Exame prevê a probabilidade de admissão de %f' % H)\n",
    "print('\\t ######################################################################################\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - L2 Regularization\n",
    "\n",
    "The standard way to avoid overfitting is called **L2 regularization**. It consists of appropriately modifying your cost function, from:\n",
    "$$J = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small  y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} \\tag{1}$$\n",
    "To:\n",
    "$$J_{regularized} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} }_\\text{cross-entropy cost} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{L2 regularization cost} \\tag{2}$$\n",
    "\n",
    "Let's modify your cost and observe the consequences.\n",
    "\n",
    "**Exercise**: Implement `compute_cost_with_regularization()` which computes the cost given by formula (2). To calculate $\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2}$  , use :\n",
    "```python\n",
    "np.sum(np.square(Wl))\n",
    "```\n",
    "Note that you have to do this for $W^{[1]}$, $W^{[2]}$ and $W^{[3]}$, then sum the three terms and multiply by $ \\frac{1}{m} \\frac{\\lambda}{2} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
